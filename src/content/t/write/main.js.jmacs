@./* global FORMAT */
@//

@import '../../text.read.jmacs'
@import '../../../share/channel.jmacs'
@import '../../../share/iris.jmacs'
@import '../../../share/writer.jmacs'

@$ B_TTL = 'ttl' === FORMAT;
@$ B_TRIG = 'trig' === FORMAT;
@$ B_QUADS = B_TRIG;

@$ S_LABEL = B_TTL? 'Turtle': 'TriG';

@$ S_CONTENT_TYPE = B_TTL? 'text/turtle': 'application/trig';

const factory = require('@{channel('core.data.factory')}');
const Writable = require('@{channel('core.class.writable')}');

// eslint-disable-next-line no-misleading-character-class
const RT_PREFIXED_NAME_NAMESPACE_VALID = /^(@{PN_PREFIX()})?$/u;
const N_MAX_STRING_BUFFER = 1 << 12;

@.{/*
const P_IRI_RDF_TYPE = 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type';
*/}

class @{S_LABEL}_Writer extends Writable {
	constructor(gc_writer={}) {
		super(gc_writer);

		let {
			prefixes: h_prefixes={},
			collections: gc_collections=null,
			debug: b_debug=false,
			style: gc_style=null,
		} = gc_writer;

		Object.assign(this, {
			_b_debug: b_debug,
			_s_indent: '\t',
			_b_simplify_default_graph: false,
		});

		@- B_QUADS
			let s_graph_keyword = '';
		@;

		// style config
		if(gc_style) {
			@- B_QUADS
				// 'graph' keyword
				let z_graph_keyword = gc_style.graph_keyword || gc_style.graphKeyword || gc_style['graph-keyword'];
				if(z_graph_keyword) {
					// boolean true
					if(true === z_graph_keyword) {
						s_graph_keyword = 'GRAPH ';
					}
					// invalid type
					else if('string' !== typeof z_graph_keyword) {
						throw new TypeError(`Invalid argument type given for 'graph' token: ${z_graph_keyword}`);
					}
					// invalid token string
					else if(!/^graph$/i.test(z_graph_keyword)) {
						throw new Error(`Graph token must equal case-insensitive "GRAPH"; found: "${z_graph_keyword}"`);
					}
					// valid graph token; append space
					else {
						s_graph_keyword = z_graph_keyword+' ';
					}
				}

				// default graph simplification
				let w_simplify_default_graph = gc_style.simplify_default_graph || gc_style.simplifyDefaultGraph || gc_style['simplify-default-graph'];
				if(w_simplify_default_graph) {
					this._b_simplify_default_graph = !!w_simplify_default_graph;
				}
			@;

			// indent
			if(gc_style.indent) {
				this._s_indent = gc_style.indent.replace(/[^\s]/g, '');
			}
		}

		@- B_QUADS
			// set graph token
			this._s_graph_keyword = s_graph_keyword;
		@;

			@.{/*
			// 'a' token
			let b_alias_rdf_type = false;
			if(gc_tokens.a) {
				let z_token = gc_tokens.graph;

				// boolean true
				if(true === gc_tokens.a) {
					b_alias_rdf_type = true;
				}
				// invalid type
				else if('boolean' !== typeof z_token) {
					throw new TypeError(`Expected boolean value; invalid argument type given for 'a' token: ${z_token}`);
				}
			}

			// set alias rdf type
			this.alias_rdf_type = b_alias_rdf_type;
		}
			*/}

		// custom collection keys
		if(gc_collections) {
			// serialize collection object
			this._serialize_collection_object = function(a_collection, n_nest_level) {
				// transcode collection object
				let hc2_transcoded = this._transcode_collection(a_collection);

				// serialize object
				return this._encode_objects(hc2_transcoded, n_nest_level);
			};
		}

		// serialize initial prefix mappings
		let s_prefixes = '';
		try {
			// each user-defined prefix
			for(let s_prefix_id in h_prefixes) {
				// invalid prefix id
				if(!RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
					throw new Error(`Invlalid prefix id for @{S_CONTENT_TYPE} RDF serialization format: '${s_prefix_id}'`);
				}
				
				// append to string
				s_prefixes += `@prefix ${s_prefix_id}: ${factory.namedNode(h_prefixes[s_prefix_id]).verbose()} .\n`;
			}
		}
		// serialization error
		catch(e_serialize) {
			setTimeout(() => {
				this.emit('error', e_serialize);
			}, 0);
		}

		// push prefixes
		if(s_prefixes) this.push(s_prefixes);
	}

	// serialize prefixes
	_serialize_prefixes(h_prefixes) {
		// build prefixes string
		let s_prefixes = (@{XC_STATE_DATA} === this._xc_state)? '\n\n': '';

		// update state
		this._xc_state = @{XC_STATE_INITIAL};

		// clone prefixes
		this._h_prefixes = {...this._h_prefixes};

		// each user-defined prefix
		for(let s_prefix_id in h_prefixes) {
			// invalid prefix id
			if(!RT_PREFIXED_NAME_NAMESPACE_VALID.test(s_prefix_id)) {
				throw new Error(`Invlalid prefix id for @{S_CONTENT_TYPE} RDF serialization format: '${s_prefix_id}'`);
			}

			// append to string
			s_prefixes += `@prefix ${s_prefix_id}: ${factory.namedNode(h_prefixes[s_prefix_id]).verbose()} .\n`;

			// set prefix
			this._h_prefixes[s_prefix_id] = h_prefixes[s_prefix_id];
		}

		// recache
		factory.cache_prefixes(this._h_prefixes);

		// return prefix string
		return s_prefixes;
	}

@> serialize_cn(n_n)
	@.{
		let b_c4 = false;
		let s_name = 'triples';
		if(4 === n_n) {
			s_name = 'quads';
			b_c4 = true;
		}
	}
	@//@object-literal
	// serialize c@{n_n} hash
	_serialize_c@{n_n}(hc@{n_n}_@{s_name}) {
		@//@
		let {
			_h_prefixes: h_prefixes,
			_s_indent: s_indent,
			@.{/*alias_rdf_type: b_alias_rdf_type,*/}
		} = this;

		// break line if non-data state
		let s_write = @{XC_STATE_DATA} !== this._xc_state? '\n': '';

		// update state
		this._xc_state = @{XC_STATE_DATA};

		@- b_c4
			// force default graph brace
			let b_simplify_default_graph = this._b_simplify_default_graph;

			// graph token
			let s_graph_keyword = this._s_graph_keyword;
			
			// each graph
			for(let sc1_graph in hc4_quads) {
				// directive
				if('`' === sc1_graph[0]) {
					s_write += this._encode_directive(sc1_graph, hc4_quads[sc1_graph]);
					continue;
				}

				// serialize open graph
				let st_graph = factory.c1_node(sc1_graph, h_prefixes).terse(h_prefixes);
				s_write += s_graph_keyword+(st_graph
					? st_graph+' {'
					: (b_simplify_default_graph? '': '{')
				)+'\n';

				// simplify default graph implies no indent
				let s_indent_root = (!st_graph && b_simplify_default_graph)? '': s_indent;

				// update state
				this._xc_state = @{XC_STATE_DATA};

				// ref triples
				let hc3_triples = hc4_quads[sc1_graph];
		@;

			// triple delimiter
			let s_delim_triples = '';

			// each subject
			for(let sc1_subject in hc3_triples) {
				// directive
				if('`' === sc1_subject[0]) {
					s_write += s_delim_triples+@{b_c4? 's_indent_root+': ''}this._encode_directive(sc1_subject, hc3_triples[sc1_subject]);

					// do not break next line
					s_delim_triples = '';
					continue;
				}

				// position before subject
				let i_triples = s_write.length;

				// serialize subject
				s_write += s_delim_triples+@{b_c4? 's_indent_root+': ''}factory.c1_node(sc1_subject, h_prefixes).terse(h_prefixes)+' ';

				// pair indent & terminator
				let s_indent_pairs = '';
				let s_term_pairs = '';

				// ref pairs
				let hc2_pairs = hc3_triples[sc1_subject];

				// position before pairs
				let i_pairs = s_write.length;

				// were objects written?
				let b_empty = true;

				// each predicate
				for(let sc1_predicate in hc2_pairs) {
					// directive
					if('`' === sc1_predicate[0]) {
						// break line
						s_write += (s_indent_pairs? s_term_pairs: '\n')+s_indent@{b_c4? '+s_indent_root': ''};

						// serialize directive
						s_write += this._encode_directive(sc1_predicate, hc2_pairs[sc1_predicate]);

						// pair already terminated
						s_term_pairs = '';

						// indent next pair
						s_indent_pairs = s_indent@{b_c4? '+s_indent_root': ''};
						continue;
					}

					// ref objects
					let z_objects = hc2_pairs[sc1_predicate];

					// serialize objects
					let st_objects = this._encode_objects(z_objects);

					// no objects; skip pair
					if(!st_objects) continue;

					// not empty
					b_empty = false;

					// cannot use blank node in predicate position
					if('_' === sc1_predicate[0] && ':' === sc1_predicate[1]) {
						throw new Error(`Cannot use blank node in predicate position of c@{n_n} hash;@{b_c4? ` graph:'\${sc1_graph}',`: ''} subject:'${sc1_subject}', predicate:'${sc1_predicate}'`);
					}

					// create predicate
					let kt_predicate = factory.c1_named_node(sc1_predicate, h_prefixes);

					// tersify rdf:type
					let st_predicate = kt_predicate.isRdfTypeAlias? 'a': kt_predicate.terse(h_prefixes);

					// serialize predicate and object(s)
					s_write += s_term_pairs+s_indent_pairs+st_predicate+' '+st_objects;

					// update state
					this._xc_state = @{XC_STATE_DATA};

					// // string buffer became too large
					// if(s_write.length >= N_MAX_STRING_BUFFER) {
					// 	debugger;
					// }

					// terminate next pair
					s_term_pairs = ' ;\n';

					// indent next pair
					s_indent_pairs = s_indent@{b_c4? '+s_indent_root': ''};
				}

				// empty triples; cut out
				if(b_empty) {
					s_write = s_write.slice(0, i_triples)+s_write.slice(i_pairs);
					continue;
				}

				// delimit triple(s)
				s_delim_triples = '\n';

				// close triple
				s_write += `${s_term_pairs? ' ': s_indent_pairs}.\n`; // @{b_c4? '\\n': ''}
			}

		@- b_c4
				// close graph
				s_write += ((st_graph || !b_simplify_default_graph)? '}\n': '')+'\n';

			}
		@:
			s_write += '\n';
		@;

		return s_write;
	}
@;

	@{serialize_cn(3)}

	@- B_QUADS
		@{serialize_cn(4)}
	@;

	@//@object-literal
	// write objects
	_encode_objects(z_objects, n_nest_level=1) {
		let {
			_h_prefixes: h_prefixes,
			_s_indent: s_indent,
			_hm_coercions: hm_coercions,
		} = this;

		// deduce object value type
		switch(typeof z_objects) {
			// concise-term string
			case 'string': return factory.c1(z_objects, h_prefixes).terse(h_prefixes);

			// numeric type
			case 'number': return factory.number(z_objects).terse(h_prefixes);

			// boolean type
			case 'boolean': return factory.boolean(z_objects).terse(h_prefixes);

			// object
			case 'object': {
				// null; reject
				if(null === z_objects) throw new Error('Refusing to serialize null value given as an object of quad');

				// array, list of objects
				if(Array.isArray(z_objects) || z_objects instanceof Set) {
					let s_write = '';

					// object terminator
					let s_term_object = '';

					// each object
					for(let z_item of z_objects) {
						// item is an array; write RDF collection
						if(Array.isArray(z_item)) {
							s_write += s_term_object + this._serialize_collection_object(z_item, n_nest_level);
						}
						// non-array
						else {
							// recurse on item
							s_write += s_term_object + this._encode_objects(z_item, n_nest_level);
						}

						// terminate next object
						s_term_object = ', ';
					}

					return s_write;
				}
				// plain object, blank node
				else if(Object === z_objects.constructor) {
					// open blank node block
					let s_write = '[';

					// whether the block is empty
					let b_empty = true;

					// each pair
					for(let sc1_predicate in z_objects) {
						// block is not empty
						b_empty = false;

						// terminate previous pair
						s_write += '\n'+s_indent.repeat(@{B_QUADS? 2: 1}+n_nest_level);

						// directive; serialize it
						if('`' === sc1_predicate[0]) {
							s_write += this._encode_directive(sc1_predicate, z_objects[sc1_predicate]);
							continue;
						}

						// write predicate and object(s)
						s_write += factory.c1(sc1_predicate, h_prefixes).terse(h_prefixes) + ' '
							+ this._encode_objects(z_objects[sc1_predicate], n_nest_level+1) +' ;';
					}

					// close blank node block
					s_write += (b_empty? '': '\n'+s_indent.repeat(@{B_QUADS? '1+': ''}n_nest_level))+']';

					// serialize current predicate to blank node
					return s_write;
				}
				// coercable instance
				else if(hm_coercions.has(z_objects.constructor)) {
					// convert javascript object to term object
					let kt_converted = hm_coercions.get(z_objects.constructor).apply(this, [z_objects, n_nest_level]);

					// serialize
					return kt_converted.terse(h_prefixes);
				}
				// graphy term
				else if(z_objects.isGraphyTerm) {
					return z_objects.terse(h_prefixes);
				}
				// RDFJS term
				else if(z_objects.termType) {
					return factory.from.term(z_objects).terse(h_prefixes);
				}
			}

			// fallthrough: other
			default: {
				throw new Error(`Bad type for RDF object: [${typeof z_objects}] ${z_objects? z_objects.constructor: z_objects}`);
			}
		}
	}

	// serialize collection object
	_serialize_collection_object(a_collection, n_nest_level) {
		let s_indent = this._s_indent;

		// open collection block
		let s_write = '(';

		// each item
		for(let z_item of a_collection) {
			let s_objects = '';

			// item is array; serialize as sub-collection
			if(Array.isArray(z_item)) {
				s_objects = this._serialize_collection_object(z_item, n_nest_level+1);
			}
			// non-array item
			else {
				s_objects = this._encode_objects(z_item, n_nest_level+1);
			}
			
			// serialize collection
			s_write += '\n'+s_indent.repeat(@{B_QUADS? 2: 1}+n_nest_level)+s_objects;
		}

		// break line if anything was written (including comments)
		if(a_collection.length) s_write += '\n'+s_indent.repeat(@{B_QUADS? '1+': ''}n_nest_level);

		// close collection block
		s_write += ')';

		return s_write;
	}

	// rdfjs quad
	_serialize_quad(g_quad) {
		let h_prefixes = this._h_prefixes;
		let kq_quad = factory.from.quad(g_quad);

		@- B_QUADS
			let st_graph = kq_quad.graph.terse(h_prefixes);
		@;

		// serialize quad
		this._s_push += (@{XC_STATE_DATA} !== this._xc_state? '\n': '')
			@- B_QUADS
				+this._s_graph_keyword+(st_graph? st_graph+' ': '')+'{\n\t'
			@;
			+kq_quad.subject.terse(h_prefixes)+' '
			+kq_quad.predicate.terse(h_prefixes)+' '
			+kq_quad.object.terse(h_prefixes)+' .\n@{B_QUADS? '\'': '\\n\';'}
			@- B_QUADS
				+'}\n\n';
			@;
			;

		// update state
		this._xc_state = @{XC_STATE_DATA};
	}

}

Object.assign(@{S_LABEL}_Writer.prototype, {
	anonymous_blank_nodes: true,
	_serialize_c3r: @{S_LABEL}_Writer.prototype._serialize_c3,
	_serialize_c4r: @{S_LABEL}_Writer.prototype._serialize_c4,
	_serialize_comment: Writable.prototype._serialize_hash_comment,
});

module.exports = function(gc_writer) {
	return new @{S_LABEL}_Writer(gc_writer);
};
